<?xml version="1.0" encoding="UTF-8"?>
<project basedir="." name="download-convert-upload" default="build">
	<property file="upload.properties"/>
	<property name="baseurl" value="http://www.data.gouv.fr/fr/"/>
		
	<!-- Necessary to set full path in Linux as PATH in not available in cron job -->
	<condition property="curl" value="curl.exe" else="/usr/bin/curl">
		<os family="windows"/>
	</condition>
	<condition property="tarql" value="tarql.bat" else="/home/admin/tarql/bin/tarql">
		<os family="windows"/>
	</condition>
	<condition property="fuseki" value="fuseki-server.bat" else="/home/admin/fuseki/fuseki-server">
		<os family="windows"/>
	</condition>
	<condition property="livedataDownloaded" value="true" else="false">
		<available file="rdf/livedata.trig"></available>
	</condition>
	<tstamp>
		<!-- With - to be filename-compatible -->
		<format property="now"
			pattern="yyyy-MM-dd'T'HH-mm-ss"/>
	</tstamp>
	<tstamp>
		<!-- Standard dateTime format -->
		<format property="start"
			pattern="yyyy-MM-dd'T'HH:mm:ss"/>
	</tstamp>
	
	<extension-point name="quick" depends="publish"/>
	<extension-point name="build" depends="convert, publish"/>
	
	<target name="download">
  	<echo>[DOWNLOAD]</echo>
  	<mkdir dir="csv/history"/>
		<echo>Downloading datasets.csv...</echo>
  	<get
  		verbose="false"
  		src="${baseurl}datasets.csv"
  		dest="csv/datasets.csv"/>
  	<echo>Downloading resources.csv...</echo>
  	<get
  		verbose="false"
  		src="${baseurl}resources.csv"
  		dest="csv/resources.csv"/>
		<echo>Downloading reuses.csv...</echo>
		<get
			verbose="false"
			src="${baseurl}reuses.csv"
			dest="csv/reuses.csv"/>
		<echo>Downloading organizations.csv...</echo>
		<get
			verbose="false"
			src="${baseurl}organizations.csv"
			dest="csv/organizations.csv"/>
  </target>
	
	<target name="clean" depends="download">
		<echo>[CLEAN]</echo>
		<mkdir dir="csv/temp/"/>
		<echo>Removing empty lines that mess with TARQL querying...</echo>
		<copy todir="csv/temp/">
			<fileset dir="csv/" includes="*.csv"/>
			<filterchain>
				<ignoreblank/>	
			</filterchain>
		</copy>
		<move todir="csv/">
			<fileset dir="csv/temp/" includes="*.csv"/>
		</move>
		<echo> </echo>
		<echo>Unescaping escaped quotes that are followed by a semicolon (\";)...</echo>
		<replaceregexp flags="gs" file="csv/datasets.csv" encoding="utf-8" match='\\";' replace='";'/>
		<echo>Replacing "." with "_" in headers to ease TARQL processing...</echo>
		<replace file="csv/datasets.csv" encoding="utf-8" token=';"metric.' value=';"metric_'/>
		<replace file="csv/resources.csv" encoding="utf-8"  token=';"checksum.' value=';"checksum_'/>
		<replace file="csv/resources.csv" encoding="utf-8"  token='"dataset.' value='"dataset_'/>
		<replace file="csv/reuses.csv" encoding="utf-8" token=';"metric.' value=';"metric_'/>
		<replace file="csv/organizations.csv" encoding="utf-8" token=';"metric.' value=';"metric_'/>
		<echo>Deleting temp directory...</echo>
		<delete dir="csv/temp/"/>
	</target>
	
	<target name="convert" depends="clean">
		<echo>[CONVERT]</echo>
		<mkdir dir="rdf/history"/>
		<echo>Querying datasets.csv with a SPARQL CONSTRUCT using TARQL (thanks @cygri)...</echo>
		<exec executable="${tarql}" searchpath="true" output="rdf/datasets.ttl">
			<arg line="sparql/construct-datasets.rq"/>
		</exec>
		<echo>Querying resources.csv with a SPARQL CONSTRUCT using TARQL (thanks @cygri)...</echo>
		<exec executable="${tarql}" searchpath="true" output="rdf/resources.ttl">
			<arg line="sparql/construct-resources.rq"/>
		</exec>
		<echo>Querying reuses.csv with a SPARQL CONSTRUCT using TARQL (thanks @cygri)...</echo>
		<exec executable="${tarql}" searchpath="true" output="rdf/reuses.ttl">
			<arg line="sparql/construct-reuses.rq"/>
		</exec>
		<echo>Querying organizations.csv with a SPARQL CONSTRUCT using TARQL (thanks @cygri)...</echo>
		<exec executable="${tarql}" searchpath="true" output="rdf/organizations.ttl">
			<arg line="sparql/construct-organizations.rq"/>
		</exec>
<!--		<echo>Archiving RDF...</echo>
		<copy tofile="rdf/history/${now}_datasets.ttl">
			<file basedir="rdf/" name="datasets.ttl"/>
		</copy>
		<copy tofile="rdf/history/${now}_resources.ttl">
			<file basedir="rdf/" name="resources.ttl"/>
		</copy> 	
		<copy tofile="rdf/history/${now}_reuses.ttl">
			<file basedir="rdf/" name="reuses.ttl"/>
		</copy>
		<copy tofile="rdf/history/${now}_organizations.ttl">
			<file basedir="rdf/" name="organizations.ttl"/>
		</copy>-->
		<antcall target="upload_temp"/>
	</target>
	
	<target name="upload_temp">
		<echo>[TEMPORARY UPLOAD]</echo>
		<echo>Uploading datasets.ttl to the postprocessing repository...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X PUT"/>
			<arg line="--data-binary @'rdf/datasets.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?graph=${postprocessingGraphUri}'"/>
		</exec>
		<echo>Uploading resources.ttl to the postprocessing repository...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'rdf/resources.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?graph=${postprocessingGraphUri}'"/>
		</exec>		
		<echo>Uploading reuses.ttl to the postprocessing repository...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'rdf/reuses.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?graph=${postprocessingGraphUri}'"/>
		</exec>	
		<echo>Uploading organizations.ttl to the postprocessing repository...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'rdf/organizations.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?graph=${postprocessingGraphUri}'"/>
		</exec>	
	</target>
	
	<target name="postprocessing" depends="upload_temp">
		<echo>[POSTPROCESSING]</echo>
		<echo>Populating the graph URI in the queries...</echo>
		<mkdir dir="sparql/temp/"/>
		<copy todir="sparql/temp/" overwrite="yes">
			<fileset dir="sparql/" includes="postprocessing*"/>
		</copy>
		<replace dir="sparql/temp/" value="${postprocessingGraphUriDecoded}">
			<include name="**/*.*"/>
			<replacetoken>urn:graph:postprocessing</replacetoken>
		</replace>
		<echo>Creating relation dataset ~> organization...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-dataset-org.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>
		<echo>Creating relation reuse ~> organization...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-reuse-org.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>
		<echo>Creating relation reuse ~> dataset...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true" >
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-reuse-dataset.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>			
		<echo>Creating invert relation of dct:publisher: dgfr:published...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true" >
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-published.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>	
		<echo>Uploading points value into dedicated graph...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X PUT"/>
			<arg line="--data-binary @'turtle/points.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?graph=urn%3Agraph%3ApointsValues'"/>
		</exec>
		<echo>Calculating popularity points and aggregates for datasets, reuses, resources and organizations...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true" >
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-popularity-points.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>
		<echo>Gathering collected data about resources...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true" >
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/postprocessing-resources-data.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>
		<delete dir="sparql/temp/"/>
		
	</target>
	
	<target name="metadata" depends="postprocessing">
		<echo>[METADATA]</echo>
		<tstamp>
			<!-- <tstamp> returns the same timestamp all over the script. It's consequently
			better to simply get a date (for now)-->
			<format property="end"
				pattern="yyyy-MM-dd"/>
		</tstamp>
		<mkdir dir="turtle/temp"/>
		<echo>Replacing placeholders in VoID and PROV metadata...</echo>
		<copy todir="turtle/temp">
			<fileset dir="turtle/" includes="*.ttl"/>
		</copy>
		<replace token="@startDate" value="${start}">
			<fileset dir="turtle/temp" includes="*.ttl"/>
		</replace>
		<replace token="@endDate" value="${end}">
			<fileset dir="turtle/temp" includes="*.ttl"/>
		</replace>
		<echo>Uploading metadata to the main graph of the repository...</echo>
		<exec executable="${curl}" searchpath="true">
			<arg line="-s -X PUT"/>
			<arg line="--data-binary @'turtle/temp/prov.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?default'"/>
		</exec>
		<exec executable="${curl}" searchpath="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'turtle/temp/void.ttl'"/>
			<arg line="-H 'Content-type:text/turtle'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}?default'"/>
		</exec>
		<delete dir="turtle/temp"/>
	</target>
	
	<target name="publish" depends="metadata">
		<echo>[PUBLISH]</echo>
		<echo>Populating the graph URI in the query...</echo>
		<mkdir dir="sparql/temp/"/>
		<copy todir="sparql/temp/" overwrite="yes">
			<fileset dir="sparql/" includes="replace*"/>
		</copy>
		<replace file="sparql/temp/replace-production-graph.ru" value="${postprocessingGraphUriDecoded}">
			<include name="**/*.*"/>
			<replacefilter token="urn:graph:postprocessing" value="${postprocessingGraphUriDecoded}"/>
			<replacefilter token="urn:graph:production" value="${graphUriDecoded}"/>
		</replace>
		<echo>Replacing old production data with new data...</echo>
		<exec executable="${curl}" searchpath="true" failonerror="true">
			<arg line="-s -X POST"/>
			<arg line="--data-binary @'sparql/temp/replace-production-graph.ru'"/>
			<arg line="-H 'Content-type:application/sparql-update'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.sparqlUpdate.url}'"/>
		</exec>
		<delete dir="sparql/temp/"/>
	</target>
	
	<target name="download-livedata" unless="${livedataDownloaded}">
		<echo>[DOWNLOAD LIVE DATA]</echo>
		<echo>Downloading live data as Trig (Turtle with graphs)...</echo>
		<get
			verbose="false"
			src="${live.repository.get.url}"
			dest="rdf/livedata.trig"/>
	</target>
	
	<target name="livedata" depends="download-livedata">
		<echo>[UPLOAD LIVE DATA]</echo>
		<echo>Uploading live data into the local repository...</echo>
		<exec executable="${curl}" searchpath="true">
			<arg line="-s -X PUT"/>
			<arg line="--data-binary @'rdf/livedata.trig'"/>
			<arg line="-H 'Content-type:text/trig'"/>
			<arg line="-u ${repository.user}:${repository.password}"/>
			<arg line="'${repository.put.url}'"/>
		</exec>
	</target>
</project>

